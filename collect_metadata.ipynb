{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76358b80",
   "metadata": {
    "id": "76358b80"
   },
   "source": [
    "# CS-7643 Deep Learning Final Project\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "#### by Zhiyin (Steven) Lu and Yixuan (Elliot) Xie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cd7e09",
   "metadata": {
    "id": "79cd7e09"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# %cd drive/MyDrive/cs7643_final_project\n",
    "# %ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e17cedf",
   "metadata": {
    "id": "8e17cedf"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7a7eb",
   "metadata": {
    "id": "26b7a7eb"
   },
   "outputs": [],
   "source": [
    "# get scan and mask image information and organize into a dataframe\n",
    "scan_dir = './data/scans/train/**/*.png'\n",
    "mask_dir = './data/masks/train/**/*.npy'\n",
    "save_dir = './data/data.csv'\n",
    "save_debug_dir = './data/debug.csv'\n",
    "\n",
    "scan_path = sorted(glob.glob(scan_dir, recursive=True))\n",
    "mask_path = sorted(glob.glob(mask_dir, recursive=True))\n",
    "data = pd.DataFrame(data={'scan_path': scan_path, 'mask_path': mask_path})\n",
    "\n",
    "# extract information into separate columns\n",
    "data['id'] = data.scan_path.map( lambda x: x.split('/')[-3] + '_' + '_'.join(x.split('/')[-1].split('_')[:2]) )\n",
    "data['case'] = data.id.map( lambda x: int(x.split('_')[0][4:]) )\n",
    "data['day'] = data.id.map( lambda x: int(x.split('_')[1][3:]) )\n",
    "data['slice'] = data.id.map( lambda x: int(x.split('_')[-1]) )\n",
    "data['height'] = data.scan_path.map( lambda x: int(x.split('/')[-1].split('_')[2]) )\n",
    "data['width'] = data.scan_path.map( lambda x: int(x.split('/')[-1].split('_')[3]) )\n",
    "\n",
    "# get the segmentation information from train.csv and organize into a 'masks' dataframe\n",
    "train_csv_dir = './data/train.csv'\n",
    "train_csv = pd.read_csv(train_csv_dir)\n",
    "train_csv.segmentation = train_csv.segmentation.fillna('')\n",
    "train_csv['rle_len'] = train_csv.segmentation.map(len)\n",
    "\n",
    "# group segmentation into lists and calculate the length of the segmentation list\n",
    "seg = train_csv.groupby(['id'])['segmentation'].agg(list).to_frame()\n",
    "rle_len = train_csv.groupby(['id'])['rle_len'].agg(sum).to_frame()\n",
    "\n",
    "# merge and add segmentation list and rle_length to the 'mask_info' dataframe\n",
    "mask_info = seg.merge(rle_len, on=['id'])\n",
    "mask_info['empty'] = (mask_info['rle_len'] == 0)\n",
    "\n",
    "# merge 'scans' and 'masks' into one dataframe based on IDs\n",
    "data = data.merge(mask_info, on=['id'])\n",
    "\n",
    "# Total: 38496\n",
    "display(data)\n",
    "\n",
    "data.to_csv(save_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nLHkmV6zHDKJ",
   "metadata": {
    "id": "nLHkmV6zHDKJ"
   },
   "outputs": [],
   "source": [
    "##### RANDOM SAMPLING TO GET A SMALL DATASET FOR DEBUG PURPOSE #####\n",
    "debug = data.sample(n=20, random_state=1)\n",
    "\n",
    "display(debug)\n",
    "\n",
    "debug.to_csv(save_debug_dir, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "clean_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
